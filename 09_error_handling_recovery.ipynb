{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71ed69ba",
   "metadata": {},
   "source": [
    "# Tutorial 09: Error Handling & Recovery\n",
    "\n",
    "##  Learning Objectives\n",
    "By the end of this tutorial, you will:\n",
    "- Implement **retry logic** for transient failures\n",
    "- Create **fallback strategies** when operations fail\n",
    "- Build **circuit breakers** to prevent cascading failures\n",
    "- Use **error boundaries** to contain failures\n",
    "- Implement **graceful degradation** for partial failures\n",
    "- Log and monitor errors for observability\n",
    "- Understand **when to retry vs fail fast**\n",
    "\n",
    "##  Prerequisites\n",
    "\n",
    "Before starting this tutorial, you should have completed:\n",
    "- **Tutorial 06: Multi-Agent Workflows** (Sequential, Concurrent patterns)\n",
    "- **Tutorial 07: Advanced Workflows** (WorkflowBuilder, Custom Executors)\n",
    "- **Tutorial 08: Human-in-the-Loop** (Approval gates, Interactive workflows)\n",
    "\n",
    "##  Why Error Handling Matters\n",
    "\n",
    "In production AI systems, things WILL go wrong:\n",
    "- ðŸ”´ **API Rate Limits** - Azure OpenAI throttles requests\n",
    "- ðŸ”´ **Network Timeouts** - Temporary connectivity issues\n",
    "- ðŸ”´ **Model Failures** - Invalid responses or context limits\n",
    "- ðŸ”´ **Resource Exhaustion** - Out of memory, quota exceeded\n",
    "- ðŸ”´ **External Dependencies** - Third-party APIs down\n",
    "\n",
    "### Error Handling Strategies\n",
    "\n",
    "| Strategy | When to Use | Example |\n",
    "|----------|-------------|---------|\n",
    "| **Retry** | Transient failures (network, rate limits) | Exponential backoff |\n",
    "| **Fallback** | Service degradation | Use simpler model, cached data |\n",
    "| **Circuit Breaker** | Cascading failures | Stop calling failing service |\n",
    "| **Timeout** | Hanging operations | Set max execution time |\n",
    "| **Graceful Degradation** | Partial failures | Return partial results |\n",
    "| **Fail Fast** | Invalid input, logic errors | Immediate exception |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7391806f",
   "metadata": {},
   "source": [
    "## Step 1: Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc9635b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Imports successful!\n",
      "ðŸ›¡ Ready to build resilient AI systems!\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from typing import Optional, Any\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "from enum import Enum\n",
    "\n",
    "from agent_framework import (\n",
    "    # Workflow builders\n",
    "    WorkflowBuilder,\n",
    "    SequentialBuilder,\n",
    "    # Core components\n",
    "    Executor,\n",
    "    AgentExecutor,\n",
    "    handler,\n",
    "    WorkflowContext,\n",
    "    # Events\n",
    "    WorkflowOutputEvent,\n",
    "    # Message types\n",
    "    ChatMessage,\n",
    "    Role,\n",
    ")\n",
    "from agent_framework.azure import AzureAIAgentClient\n",
    "from azure.identity.aio import AzureCliCredential\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "print(\" Imports successful!\")\n",
    "print(\"ðŸ›¡ Ready to build resilient AI systems!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e412b6b",
   "metadata": {},
   "source": [
    "## Step 2: Pattern 1 - Retry Logic with Exponential Backoff\n",
    "\n",
    "The most common error handling pattern: retry transient failures with increasing delays.\n",
    "\n",
    "### Flow\n",
    "```\n",
    "Execute â†’ Success âœ“\n",
    "       â†’ Failure â†’ Wait â†’ Retry â†’ Success âœ“\n",
    "                        â†’ Failure â†’ Wait (2x) â†’ Retry â†’ Success âœ“\n",
    "                                              â†’ Failure â†’ Give up âœ—\n",
    "```\n",
    "\n",
    "### Key Concepts\n",
    "- **Exponential Backoff** - Double wait time after each retry\n",
    "- **Max Retries** - Limit retry attempts to prevent infinite loops\n",
    "- **Retry-able Errors** - Distinguish transient vs permanent failures\n",
    "- **Jitter** - Add randomness to prevent thundering herd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "395d5e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PATTERN 1: Retry Logic with Exponential Backoff\n",
      "======================================================================\n",
      "\n",
      "Simulating API with random failures...\n",
      "\n",
      " Request: Process important data\n",
      "\n",
      "\n",
      " Retry attempt 1/4\n",
      " Attempt 1: SUCCESS! Processed: Process important data\n",
      "\n",
      "======================================================================\n",
      " FINAL RESULT\n",
      "======================================================================\n",
      " Attempt 1: SUCCESS! Processed: Process important data\n",
      "======================================================================\n",
      "\n",
      " What Happened:\n",
      "  1âƒ£  Service failed randomly (60% failure rate)\n",
      "  2âƒ£  Retry logic kicked in with exponential backoff\n",
      "  3âƒ£  Delays: 0.5s â†’ 1.0s â†’ 2.0s (+ jitter)\n",
      "  4âƒ£  Either succeeded on retry or failed after max attempts\n",
      "\n",
      " Production Settings:\n",
      "  â€¢ API rate limits: 3-5 retries, 1s initial, 2x backoff\n",
      "  â€¢ Network timeouts: 2-3 retries, 0.5s initial, 1.5x backoff\n",
      "  â€¢ Always add jitter to prevent thundering herd\n"
     ]
    }
   ],
   "source": [
    "async def retry_logic_demo():\n",
    "    \"\"\"\n",
    "    Demonstrate retry logic with exponential backoff.\n",
    "    Simulates API failures and automatic recovery.\n",
    "    \"\"\"\n",
    "    print(\"=\"*70)\n",
    "    print(\"PATTERN 1: Retry Logic with Exponential Backoff\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\nSimulating API with random failures...\\n\")\n",
    "    \n",
    "    # Simulated unreliable executor\n",
    "    class UnreliableExecutor(Executor):\n",
    "        \"\"\"Simulates random failures to demonstrate retry logic\"\"\"\n",
    "        \n",
    "        def __init__(self, failure_rate=0.6):\n",
    "            super().__init__(id=\"unreliable_service\")\n",
    "            self.failure_rate = failure_rate\n",
    "            self.attempt_count = 0\n",
    "        \n",
    "        @handler\n",
    "        async def process(self, request: str, ctx: WorkflowContext[str, str]) -> None:\n",
    "            self.attempt_count += 1\n",
    "            \n",
    "            # Simulate random failure\n",
    "            if random.random() < self.failure_rate:\n",
    "                error_msg = f\" Attempt {self.attempt_count}: Service temporarily unavailable\"\n",
    "                print(error_msg)\n",
    "                raise RuntimeError(\"Service unavailable - simulated failure\")\n",
    "            else:\n",
    "                result = f\" Attempt {self.attempt_count}: SUCCESS! Processed: {request}\"\n",
    "                print(result)\n",
    "                await ctx.yield_output(result)\n",
    "    \n",
    "    # Retry wrapper executor\n",
    "    class RetryExecutor(Executor):\n",
    "        \"\"\"Wraps another executor with retry logic\"\"\"\n",
    "        \n",
    "        def __init__(\n",
    "            self, \n",
    "            inner_executor: Executor,\n",
    "            max_retries: int = 3,\n",
    "            initial_delay: float = 1.0,\n",
    "            backoff_factor: float = 2.0,\n",
    "            add_jitter: bool = True\n",
    "        ):\n",
    "            super().__init__(id=f\"retry_{inner_executor.id}\")\n",
    "            self.inner_executor = inner_executor\n",
    "            self.max_retries = max_retries\n",
    "            self.initial_delay = initial_delay\n",
    "            self.backoff_factor = backoff_factor\n",
    "            self.add_jitter = add_jitter\n",
    "        \n",
    "        @handler\n",
    "        async def execute_with_retry(self, request: str, ctx: WorkflowContext[str, str]) -> None:\n",
    "            \"\"\"Execute with exponential backoff retry logic\"\"\"\n",
    "            \n",
    "            delay = self.initial_delay\n",
    "            last_error = None\n",
    "            \n",
    "            for attempt in range(self.max_retries + 1):\n",
    "                try:\n",
    "                    print(f\"\\n Retry attempt {attempt + 1}/{self.max_retries + 1}\")\n",
    "                    \n",
    "                    # Try to execute\n",
    "                    await self.inner_executor.process(request, ctx)\n",
    "                    return  # Success!\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    last_error = e\n",
    "                    \n",
    "                    if attempt < self.max_retries:\n",
    "                        # Calculate wait time with optional jitter\n",
    "                        wait_time = delay\n",
    "                        if self.add_jitter:\n",
    "                            # Add random jitter (0-50% of delay)\n",
    "                            jitter = random.uniform(0, delay * 0.5)\n",
    "                            wait_time += jitter\n",
    "                        \n",
    "                        print(f\"â³ Waiting {wait_time:.2f}s before retry...\")\n",
    "                        await asyncio.sleep(wait_time)\n",
    "                        \n",
    "                        # Exponential backoff\n",
    "                        delay *= self.backoff_factor\n",
    "                    else:\n",
    "                        # Max retries exceeded\n",
    "                        print(f\"\\nðŸ’¥ All {self.max_retries + 1} attempts failed!\")\n",
    "                        error_result = f\" FAILED after {self.max_retries + 1} attempts: {str(last_error)}\"\n",
    "                        await ctx.yield_output(error_result)\n",
    "    \n",
    "    # Test the retry logic\n",
    "    unreliable = UnreliableExecutor(failure_rate=0.6)  # 60% failure rate\n",
    "    retry_wrapper = RetryExecutor(\n",
    "        unreliable,\n",
    "        max_retries=3,\n",
    "        initial_delay=0.5,  # Start with 0.5s\n",
    "        backoff_factor=2.0,  # Double each time: 0.5s, 1s, 2s\n",
    "        add_jitter=True\n",
    "    )\n",
    "    \n",
    "    workflow = (\n",
    "        WorkflowBuilder()\n",
    "        .set_start_executor(retry_wrapper)\n",
    "        .build()\n",
    "    )\n",
    "    \n",
    "    # Run test\n",
    "    request = \"Process important data\"\n",
    "    print(f\" Request: {request}\\n\")\n",
    "    \n",
    "    final_output = None\n",
    "    async for event in workflow.run_stream(request):\n",
    "        if isinstance(event, WorkflowOutputEvent):\n",
    "            final_output = event.data\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\" FINAL RESULT\")\n",
    "    print(\"=\"*70)\n",
    "    if final_output:\n",
    "        print(final_output)\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    print(\"\\n What Happened:\")\n",
    "    print(\"  1âƒ£  Service failed randomly (60% failure rate)\")\n",
    "    print(\"  2âƒ£  Retry logic kicked in with exponential backoff\")\n",
    "    print(\"  3âƒ£  Delays: 0.5s â†’ 1.0s â†’ 2.0s (+ jitter)\")\n",
    "    print(\"  4âƒ£  Either succeeded on retry or failed after max attempts\")\n",
    "    print(\"\\n Production Settings:\")\n",
    "    print(\"  â€¢ API rate limits: 3-5 retries, 1s initial, 2x backoff\")\n",
    "    print(\"  â€¢ Network timeouts: 2-3 retries, 0.5s initial, 1.5x backoff\")\n",
    "    print(\"  â€¢ Always add jitter to prevent thundering herd\")\n",
    "\n",
    "await retry_logic_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0744b995",
   "metadata": {},
   "source": [
    "## Step 3: Pattern 2 - Fallback Strategies\n",
    "\n",
    "When primary service fails, fall back to alternative approach.\n",
    "\n",
    "### Flow\n",
    "```\n",
    "Try Primary Service â†’ Success âœ“\n",
    "                    â†’ Failure â†’ Try Fallback â†’ Success âœ“\n",
    "                                             â†’ Failure â†’ Error âœ—\n",
    "```\n",
    "\n",
    "### Key Concepts\n",
    "- **Primary/Secondary** - Preferred vs backup services\n",
    "- **Graceful Degradation** - Lower quality but still useful\n",
    "- **Cached Responses** - Return stale data when fresh unavailable\n",
    "- **Simplified Operations** - Use simpler model or approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad45ad8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def fallback_strategy_demo():\n",
    "    \"\"\"\n",
    "    Demonstrate fallback to simpler approach when primary fails.\n",
    "    Example: GPT-4 â†’ GPT-3.5 â†’ Cached response\n",
    "    \"\"\"\n",
    "    print(\"=\"*70)\n",
    "    print(\"PATTERN 2: Fallback Strategies\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\nTiered fallback: Advanced Model â†’ Simple Model â†’ Cache\\n\")\n",
    "    \n",
    "    # Simulated cache\n",
    "    RESPONSE_CACHE = {\n",
    "        \"weather\": \"Cached: Sunny, 72Â°F (last updated 1 hour ago)\",\n",
    "        \"news\": \"Cached: Top headlines from this morning\",\n",
    "    }\n",
    "    \n",
    "    # Fallback executor with multiple tiers\n",
    "    class FallbackExecutor(Executor):\n",
    "        \"\"\"Try multiple strategies in order until one succeeds\"\"\"\n",
    "        \n",
    "        def __init__(self):\n",
    "            super().__init__(id=\"fallback_executor\")\n",
    "            self.primary_failures = 0\n",
    "            self.fallback_successes = 0\n",
    "            self.cache_hits = 0\n",
    "        \n",
    "        async def try_advanced_model(self, request: str) -> str:\n",
    "            \"\"\"Simulate advanced model (expensive, sometimes fails)\"\"\"\n",
    "            print(\"   Trying advanced model (GPT-4)...\")\n",
    "            \n",
    "            # Simulate 50% failure rate for demo\n",
    "            if random.random() < 0.5:\n",
    "                raise RuntimeError(\"Advanced model unavailable (rate limited)\")\n",
    "            \n",
    "            return f\" GPT-4 Response: Detailed analysis of '{request}'\"\n",
    "        \n",
    "        async def try_simple_model(self, request: str) -> str:\n",
    "            \"\"\"Simulate simple model (cheaper, more reliable)\"\"\"\n",
    "            print(\"   Falling back to simple model (GPT-3.5)...\")\n",
    "            \n",
    "            # Simulate 20% failure rate\n",
    "            if random.random() < 0.2:\n",
    "                raise RuntimeError(\"Simple model also unavailable\")\n",
    "            \n",
    "            return f\" GPT-3.5 Response: Basic answer for '{request}'\"\n",
    "        \n",
    "        async def try_cache(self, request: str) -> str:\n",
    "            \"\"\"Try cached response\"\"\"\n",
    "            print(\"  ðŸ“¦ Checking cache...\")\n",
    "            \n",
    "            # Simple keyword matching\n",
    "            for key in RESPONSE_CACHE:\n",
    "                if key in request.lower():\n",
    "                    return f\" {RESPONSE_CACHE[key]}\"\n",
    "            \n",
    "            raise RuntimeError(\"No cached response available\")\n",
    "        \n",
    "        @handler\n",
    "        async def execute_with_fallback(self, request: str, ctx: WorkflowContext[str, str]) -> None:\n",
    "            \"\"\"Try strategies in order: advanced â†’ simple â†’ cache\"\"\"\n",
    "            \n",
    "            strategies = [\n",
    "                (\"Advanced Model\", self.try_advanced_model),\n",
    "                (\"Simple Model\", self.try_simple_model),\n",
    "                (\"Cache\", self.try_cache),\n",
    "            ]\n",
    "            \n",
    "            print(f\" Request: {request}\\n\")\n",
    "            \n",
    "            for strategy_name, strategy_func in strategies:\n",
    "                try:\n",
    "                    print(f\" Strategy: {strategy_name}\")\n",
    "                    result = await strategy_func(request)\n",
    "                    \n",
    "                    # Track metrics\n",
    "                    if strategy_name == \"Simple Model\":\n",
    "                        self.fallback_successes += 1\n",
    "                    elif strategy_name == \"Cache\":\n",
    "                        self.cache_hits += 1\n",
    "                    \n",
    "                    await ctx.yield_output(result)\n",
    "                    return  # Success!\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"   {strategy_name} failed: {e}\")\n",
    "                    \n",
    "                    if strategy_name == \"Advanced Model\":\n",
    "                        self.primary_failures += 1\n",
    "                    \n",
    "                    # Try next strategy\n",
    "                    continue\n",
    "            \n",
    "            # All strategies failed\n",
    "            error_msg = \" All fallback strategies exhausted - no response available\"\n",
    "            print(f\"\\nðŸ’¥ {error_msg}\")\n",
    "            await ctx.yield_output(error_msg)\n",
    "    \n",
    "    # Build workflow\n",
    "    fallback_executor = FallbackExecutor()\n",
    "    \n",
    "    workflow = (\n",
    "        WorkflowBuilder()\n",
    "        .set_start_executor(fallback_executor)\n",
    "        .build()\n",
    "    )\n",
    "    \n",
    "    # Test with multiple requests\n",
    "    test_requests = [\n",
    "        \"What's the weather like?\",\n",
    "        \"Summarize the latest tech news\",\n",
    "        \"Explain quantum computing\",  # Not in cache\n",
    "    ]\n",
    "    \n",
    "    print(\"Testing fallback strategies with multiple requests...\\n\")\n",
    "    \n",
    "    for i, request in enumerate(test_requests, 1):\n",
    "        print(\"\\n\" + \"#\"*70)\n",
    "        print(f\"TEST {i}\")\n",
    "        print(\"#\"*70 + \"\\n\")\n",
    "        \n",
    "        final_output = None\n",
    "        async for event in workflow.run_stream(request):\n",
    "            if isinstance(event, WorkflowOutputEvent):\n",
    "                final_output = event.data\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\" RESULT\")\n",
    "        print(\"=\"*70)\n",
    "        if final_output:\n",
    "            print(final_output)\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        # Small delay between tests\n",
    "        await asyncio.sleep(0.5)\n",
    "    \n",
    "    # Show metrics\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\" METRICS\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Primary failures: {fallback_executor.primary_failures}\")\n",
    "    print(f\"Fallback successes: {fallback_executor.fallback_successes}\")\n",
    "    print(f\"Cache hits: {fallback_executor.cache_hits}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    print(\"\\n What Happened:\")\n",
    "    print(\"  1âƒ£  Tried advanced model first (best quality)\")\n",
    "    print(\"  2âƒ£  On failure, fell back to simple model (good enough)\")\n",
    "    print(\"  3âƒ£  On failure, fell back to cache (stale but instant)\")\n",
    "    print(\"  4âƒ£  System degraded gracefully instead of failing completely\")\n",
    "    print(\"\\n Production Use Cases:\")\n",
    "    print(\"  â€¢ Primary DB â†’ Replica â†’ Cache\")\n",
    "    print(\"  â€¢ Live API â†’ Historical data â†’ Default message\")\n",
    "    print(\"  â€¢ Real-time â†’ Batch processed â†’ Static content\")\n",
    "\n",
    "await fallback_strategy_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b0330c",
   "metadata": {},
   "source": [
    "## Step 4: Pattern 3 - Circuit Breaker\n",
    "\n",
    "Prevent cascading failures by stopping requests to failing services.\n",
    "\n",
    "### Flow\n",
    "```\n",
    "Closed (Normal) â†’ Request â†’ Success â†’ Stay Closed\n",
    "                â†’ Request â†’ Fail (threshold) â†’ Open Circuit\n",
    "\n",
    "Open (Blocking) â†’ Wait (cooldown) â†’ Half-Open\n",
    "\n",
    "Half-Open (Testing) â†’ Request â†’ Success â†’ Close Circuit\n",
    "                    â†’ Request â†’ Fail â†’ Stay Open\n",
    "```\n",
    "\n",
    "### Key Concepts\n",
    "- **Failure Threshold** - Open circuit after N consecutive failures\n",
    "- **Cooldown Period** - Wait before testing recovery\n",
    "- **Half-Open State** - Allow test request to check if service recovered\n",
    "- **Fast Fail** - Immediately reject when circuit open (don't waste time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c803cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def circuit_breaker_demo():\n",
    "    \"\"\"\n",
    "    Demonstrate circuit breaker pattern to prevent cascading failures.\n",
    "    \"\"\"\n",
    "    print(\"=\"*70)\n",
    "    print(\"PATTERN 3: Circuit Breaker\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\nStates: Closed (OK) â†’ Open (Failing) â†’ Half-Open (Testing)\\n\")\n",
    "    \n",
    "    # Circuit breaker states\n",
    "    class CircuitState(Enum):\n",
    "        CLOSED = \"CLOSED\"        # Normal operation\n",
    "        OPEN = \"OPEN\"            # Failing, reject immediately\n",
    "        HALF_OPEN = \"HALF_OPEN\"  # Testing recovery\n",
    "    \n",
    "    # Circuit breaker executor\n",
    "    class CircuitBreakerExecutor(Executor):\n",
    "        \"\"\"Prevents cascading failures by opening circuit on repeated failures\"\"\"\n",
    "        \n",
    "        def __init__(\n",
    "            self,\n",
    "            failure_threshold: int = 3,\n",
    "            recovery_timeout: float = 5.0,\n",
    "            simulate_recovery: bool = True\n",
    "        ):\n",
    "            super().__init__(id=\"circuit_breaker\")\n",
    "            self.failure_threshold = failure_threshold\n",
    "            self.recovery_timeout = recovery_timeout\n",
    "            self.simulate_recovery = simulate_recovery\n",
    "            \n",
    "            # State tracking\n",
    "            self.state = CircuitState.CLOSED\n",
    "            self.failure_count = 0\n",
    "            self.last_failure_time: Optional[datetime] = None\n",
    "            self.total_requests = 0\n",
    "            self.rejected_requests = 0\n",
    "            \n",
    "            # Simulate service that fails then recovers\n",
    "            self.service_is_down = True\n",
    "            self.requests_until_recovery = 5\n",
    "        \n",
    "        def should_allow_request(self) -> bool:\n",
    "            \"\"\"Check if request should be allowed based on circuit state\"\"\"\n",
    "            \n",
    "            if self.state == CircuitState.CLOSED:\n",
    "                return True\n",
    "            \n",
    "            elif self.state == CircuitState.OPEN:\n",
    "                # Check if enough time has passed to try recovery\n",
    "                if self.last_failure_time:\n",
    "                    time_since_failure = datetime.now() - self.last_failure_time\n",
    "                    if time_since_failure.total_seconds() >= self.recovery_timeout:\n",
    "                        print(\"   Circuit moving to HALF-OPEN (testing recovery)\")\n",
    "                        self.state = CircuitState.HALF_OPEN\n",
    "                        return True\n",
    "                \n",
    "                # Still in cooldown\n",
    "                return False\n",
    "            \n",
    "            elif self.state == CircuitState.HALF_OPEN:\n",
    "                # Allow single test request\n",
    "                return True\n",
    "            \n",
    "            return False\n",
    "        \n",
    "        async def call_service(self, request: str) -> str:\n",
    "            \"\"\"Simulate calling external service\"\"\"\n",
    "            \n",
    "            # Simulate gradual recovery\n",
    "            if self.simulate_recovery:\n",
    "                self.requests_until_recovery -= 1\n",
    "                if self.requests_until_recovery <= 0:\n",
    "                    self.service_is_down = False\n",
    "            \n",
    "            if self.service_is_down:\n",
    "                raise RuntimeError(\"External service is down\")\n",
    "            \n",
    "            return f\" Service response: Processed '{request}'\"\n",
    "        \n",
    "        def record_success(self):\n",
    "            \"\"\"Record successful request\"\"\"\n",
    "            print(\"   Request succeeded\")\n",
    "            self.failure_count = 0\n",
    "            \n",
    "            if self.state == CircuitState.HALF_OPEN:\n",
    "                print(\"  ðŸ”“ Circuit CLOSED (service recovered)\")\n",
    "                self.state = CircuitState.CLOSED\n",
    "        \n",
    "        def record_failure(self):\n",
    "            \"\"\"Record failed request\"\"\"\n",
    "            print(\"   Request failed\")\n",
    "            self.failure_count += 1\n",
    "            self.last_failure_time = datetime.now()\n",
    "            \n",
    "            if self.failure_count >= self.failure_threshold:\n",
    "                if self.state != CircuitState.OPEN:\n",
    "                    print(f\"  ðŸš¨ Circuit OPEN (threshold {self.failure_threshold} reached)\")\n",
    "                    self.state = CircuitState.OPEN\n",
    "            \n",
    "            if self.state == CircuitState.HALF_OPEN:\n",
    "                print(\"  ðŸ”’ Circuit back to OPEN (recovery test failed)\")\n",
    "                self.state = CircuitState.OPEN\n",
    "        \n",
    "        @handler\n",
    "        async def execute(self, request: str, ctx: WorkflowContext[str, str]) -> None:\n",
    "            \"\"\"Execute with circuit breaker protection\"\"\"\n",
    "            \n",
    "            self.total_requests += 1\n",
    "            \n",
    "            # Check circuit state\n",
    "            if not self.should_allow_request():\n",
    "                self.rejected_requests += 1\n",
    "                remaining = self.recovery_timeout - (datetime.now() - self.last_failure_time).total_seconds()\n",
    "                \n",
    "                result = (\n",
    "                    f\"âš¡ CIRCUIT OPEN - Request rejected (fast fail)\\n\"\n",
    "                    f\"   Service is unhealthy. Try again in {remaining:.1f}s\"\n",
    "                )\n",
    "                print(f\"  {result}\")\n",
    "                await ctx.yield_output(result)\n",
    "                return\n",
    "            \n",
    "            # Try to execute\n",
    "            try:\n",
    "                result = await self.call_service(request)\n",
    "                self.record_success()\n",
    "                await ctx.yield_output(result)\n",
    "                \n",
    "            except Exception as e:\n",
    "                self.record_failure()\n",
    "                await ctx.yield_output(f\" Service error: {e}\")\n",
    "        \n",
    "        def get_metrics(self) -> dict:\n",
    "            \"\"\"Get circuit breaker metrics\"\"\"\n",
    "            return {\n",
    "                \"state\": self.state.value,\n",
    "                \"total_requests\": self.total_requests,\n",
    "                \"rejected_requests\": self.rejected_requests,\n",
    "                \"failure_count\": self.failure_count,\n",
    "                \"rejection_rate\": f\"{(self.rejected_requests / max(self.total_requests, 1)) * 100:.1f}%\"\n",
    "            }\n",
    "    \n",
    "    # Build workflow\n",
    "    circuit_breaker = CircuitBreakerExecutor(\n",
    "        failure_threshold=3,\n",
    "        recovery_timeout=3.0,  # 3 seconds\n",
    "        simulate_recovery=True\n",
    "    )\n",
    "    \n",
    "    workflow = (\n",
    "        WorkflowBuilder()\n",
    "        .set_start_executor(circuit_breaker)\n",
    "        .build()\n",
    "    )\n",
    "    \n",
    "    # Simulate multiple requests over time\n",
    "    print(\"Simulating requests to failing service...\\n\")\n",
    "    \n",
    "    for i in range(10):\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"REQUEST {i + 1}/10 - Circuit State: {circuit_breaker.state.value}\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        final_output = None\n",
    "        async for event in workflow.run_stream(f\"Request #{i + 1}\"):\n",
    "            if isinstance(event, WorkflowOutputEvent):\n",
    "                final_output = event.data\n",
    "        \n",
    "        if final_output:\n",
    "            print(f\"Result: {final_output}\")\n",
    "        \n",
    "        # Small delay between requests\n",
    "        await asyncio.sleep(0.5)\n",
    "    \n",
    "    # Show metrics\n",
    "    metrics = circuit_breaker.get_metrics()\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\" CIRCUIT BREAKER METRICS\")\n",
    "    print(\"=\"*70)\n",
    "    for key, value in metrics.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    print(\"\\n What Happened:\")\n",
    "    print(\"  1âƒ£  Service failed repeatedly (first 3 requests)\")\n",
    "    print(\"  2âƒ£  Circuit opened after failure threshold\")\n",
    "    print(\"  3âƒ£  Subsequent requests rejected immediately (fast fail)\")\n",
    "    print(\"  4âƒ£  After cooldown, circuit moved to half-open\")\n",
    "    print(\"  5âƒ£  Test request succeeded â†’ circuit closed\")\n",
    "    print(\"  6âƒ£  Normal operation resumed\")\n",
    "    print(\"\\n Benefits:\")\n",
    "    print(\"  â€¢ Prevent wasting resources on failing service\")\n",
    "    print(\"  â€¢ Give service time to recover\")\n",
    "    print(\"  â€¢ Fast fail instead of long timeouts\")\n",
    "    print(\"  â€¢ Automatic recovery testing\")\n",
    "\n",
    "await circuit_breaker_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99edba6",
   "metadata": {},
   "source": [
    "## Step 5: Pattern 4 - Timeout Protection\n",
    "\n",
    "Prevent operations from hanging indefinitely.\n",
    "\n",
    "### Key Concepts\n",
    "- **Operation Timeout** - Max time for single operation\n",
    "- **Workflow Timeout** - Max time for entire workflow\n",
    "- **Cancellation** - Properly stop long-running tasks\n",
    "- **Cleanup** - Release resources on timeout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6e3fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def timeout_protection_demo():\n",
    "    \"\"\"\n",
    "    Demonstrate timeout protection for long-running operations.\n",
    "    \"\"\"\n",
    "    print(\"=\"*70)\n",
    "    print(\"PATTERN 4: Timeout Protection\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\nPrevent operations from hanging indefinitely\\n\")\n",
    "    \n",
    "    # Executor with built-in timeout\n",
    "    class TimeoutExecutor(Executor):\n",
    "        \"\"\"Wraps operations with timeout protection\"\"\"\n",
    "        \n",
    "        def __init__(self, timeout_seconds: float = 5.0):\n",
    "            super().__init__(id=\"timeout_executor\")\n",
    "            self.timeout_seconds = timeout_seconds\n",
    "            self.timed_out_count = 0\n",
    "            self.completed_count = 0\n",
    "        \n",
    "        async def slow_operation(self, duration: float, request: str) -> str:\n",
    "            \"\"\"Simulate slow operation\"\"\"\n",
    "            print(f\"  â³ Starting operation (will take {duration}s)...\")\n",
    "            await asyncio.sleep(duration)\n",
    "            return f\" Completed: {request}\"\n",
    "        \n",
    "        @handler\n",
    "        async def execute_with_timeout(self, request: str, ctx: WorkflowContext[str, str]) -> None:\n",
    "            \"\"\"Execute with timeout protection\"\"\"\n",
    "            \n",
    "            # Parse duration from request (for demo)\n",
    "            try:\n",
    "                duration = float(request.split(\":\")[-1].strip().replace(\"s\", \"\"))\n",
    "            except:\n",
    "                duration = 3.0\n",
    "            \n",
    "            print(f\" Request: {request}\")\n",
    "            print(f\"â° Timeout: {self.timeout_seconds}s\")\n",
    "            \n",
    "            try:\n",
    "                # Use asyncio.wait_for for timeout\n",
    "                result = await asyncio.wait_for(\n",
    "                    self.slow_operation(duration, request),\n",
    "                    timeout=self.timeout_seconds\n",
    "                )\n",
    "                \n",
    "                self.completed_count += 1\n",
    "                print(f\"  {result}\")\n",
    "                await ctx.yield_output(result)\n",
    "                \n",
    "            except asyncio.TimeoutError:\n",
    "                self.timed_out_count += 1\n",
    "                timeout_msg = (\n",
    "                    f\"â° TIMEOUT after {self.timeout_seconds}s\\n\"\n",
    "                    f\"   Operation was taking too long and was cancelled\"\n",
    "                )\n",
    "                print(f\"  {timeout_msg}\")\n",
    "                await ctx.yield_output(timeout_msg)\n",
    "        \n",
    "        def get_metrics(self) -> dict:\n",
    "            total = self.completed_count + self.timed_out_count\n",
    "            return {\n",
    "                \"completed\": self.completed_count,\n",
    "                \"timed_out\": self.timed_out_count,\n",
    "                \"timeout_rate\": f\"{(self.timed_out_count / max(total, 1)) * 100:.1f}%\"\n",
    "            }\n",
    "    \n",
    "    # Build workflow\n",
    "    timeout_executor = TimeoutExecutor(timeout_seconds=3.0)\n",
    "    \n",
    "    workflow = (\n",
    "        WorkflowBuilder()\n",
    "        .set_start_executor(timeout_executor)\n",
    "        .build()\n",
    "    )\n",
    "    \n",
    "    # Test with various durations\n",
    "    test_requests = [\n",
    "        \"Fast operation: 1s\",\n",
    "        \"Medium operation: 2.5s\",\n",
    "        \"Slow operation: 4s\",  # Will timeout\n",
    "        \"Very slow operation: 6s\",  # Will timeout\n",
    "        \"Quick operation: 0.5s\",\n",
    "    ]\n",
    "    \n",
    "    print(\"Testing timeout protection...\\n\")\n",
    "    \n",
    "    for i, request in enumerate(test_requests, 1):\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"TEST {i}/{len(test_requests)}\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        final_output = None\n",
    "        async for event in workflow.run_stream(request):\n",
    "            if isinstance(event, WorkflowOutputEvent):\n",
    "                final_output = event.data\n",
    "        \n",
    "        print(f\"\\n Result: {final_output}\")\n",
    "    \n",
    "    # Show metrics\n",
    "    metrics = timeout_executor.get_metrics()\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\" TIMEOUT METRICS\")\n",
    "    print(\"=\"*70)\n",
    "    for key, value in metrics.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    print(\"\\n What Happened:\")\n",
    "    print(\"  1âƒ£  Operations under 3s completed successfully\")\n",
    "    print(\"  2âƒ£  Operations over 3s were cancelled (timeout)\")\n",
    "    print(\"  3âƒ£  System didn't hang waiting for slow operations\")\n",
    "    print(\"  4âƒ£  Resources released immediately on timeout\")\n",
    "    print(\"\\n Production Settings:\")\n",
    "    print(\"  â€¢ API calls: 10-30s timeout\")\n",
    "    print(\"  â€¢ Database queries: 5-10s timeout\")\n",
    "    print(\"  â€¢ Agent responses: 30-60s timeout\")\n",
    "    print(\"  â€¢ Entire workflow: 5-10 minutes timeout\")\n",
    "\n",
    "await timeout_protection_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32035793",
   "metadata": {},
   "source": [
    "##  Key Takeaways\n",
    "\n",
    "### What We Learned\n",
    "\n",
    "1. **Retry Logic**\n",
    "   - Exponential backoff: 1s â†’ 2s â†’ 4s\n",
    "   - Add jitter to prevent thundering herd\n",
    "   - Distinguish transient vs permanent failures\n",
    "   - Set max retries to prevent infinite loops\n",
    "\n",
    "2. **Fallback Strategies**\n",
    "   - Primary â†’ Secondary â†’ Tertiary\n",
    "   - Graceful degradation (good enough > nothing)\n",
    "   - Cache stale data as last resort\n",
    "   - Track which tier served the request\n",
    "\n",
    "3. **Circuit Breaker**\n",
    "   - Three states: Closed â†’ Open â†’ Half-Open\n",
    "   - Fast fail when circuit open (save resources)\n",
    "   - Automatic recovery testing\n",
    "   - Prevent cascading failures\n",
    "\n",
    "4. **Timeout Protection**\n",
    "   - Set reasonable timeouts for all operations\n",
    "   - Use asyncio.wait_for() for async operations\n",
    "   - Clean up resources on timeout\n",
    "   - Don't let system hang indefinitely\n",
    "\n",
    "### Error Handling Decision Tree\n",
    "\n",
    "```\n",
    "Error Occurs\n",
    "â”œâ”€ Is it transient? (network, rate limit)\n",
    "â”‚  â””â”€ YES â†’ Retry with exponential backoff\n",
    "â”‚\n",
    "â”œâ”€ Can we use fallback? (cached, simpler)\n",
    "â”‚  â””â”€ YES â†’ Try fallback strategy\n",
    "â”‚\n",
    "â”œâ”€ Is service repeatedly failing?\n",
    "â”‚  â””â”€ YES â†’ Open circuit breaker\n",
    "â”‚\n",
    "â”œâ”€ Is operation hanging?\n",
    "â”‚  â””â”€ YES â†’ Apply timeout\n",
    "â”‚\n",
    "â””â”€ None apply â†’ Fail fast with clear error\n",
    "```\n",
    "\n",
    "### Production Patterns\n",
    "\n",
    "```python\n",
    "# Retry with exponential backoff\n",
    "async def retry_with_backoff(func, max_retries=3):\n",
    "    delay = 1.0\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            return await func()\n",
    "        except TransientError:\n",
    "            if attempt < max_retries - 1:\n",
    "                await asyncio.sleep(delay + random.uniform(0, delay * 0.5))\n",
    "                delay *= 2\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "# Fallback chain\n",
    "async def execute_with_fallback(request):\n",
    "    try:\n",
    "        return await primary_service(request)\n",
    "    except:\n",
    "        try:\n",
    "            return await fallback_service(request)\n",
    "        except:\n",
    "            return get_cached_response(request)\n",
    "\n",
    "# Timeout protection\n",
    "async def execute_with_timeout(func, timeout=30.0):\n",
    "    try:\n",
    "        return await asyncio.wait_for(func(), timeout=timeout)\n",
    "    except asyncio.TimeoutError:\n",
    "        raise OperationTimeoutError(f\"Exceeded {timeout}s\")\n",
    "```\n",
    "\n",
    "### Combining Patterns\n",
    "\n",
    "In production, combine multiple patterns:\n",
    "\n",
    "```python\n",
    "# Retry + Fallback + Timeout\n",
    "async def robust_execute(request):\n",
    "    # 1. Try with timeout\n",
    "    try:\n",
    "        return await asyncio.wait_for(\n",
    "            retry_with_backoff(lambda: primary_service(request)),\n",
    "            timeout=30.0\n",
    "        )\n",
    "    except (TimeoutError, MaxRetriesExceeded):\n",
    "        # 2. Fall back to simpler approach\n",
    "        return await fallback_service(request)\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbba14e",
   "metadata": {},
   "source": [
    "##  Practice Exercises\n",
    "\n",
    "### Exercise 1: Smart Retry\n",
    "\n",
    "Build a retry executor that:\n",
    "- Only retries specific error types (not all errors)\n",
    "- Tracks retry success rate\n",
    "- Adjusts retry strategy based on error patterns\n",
    "\n",
    "### Exercise 2: Multi-Tier Fallback\n",
    "\n",
    "Create a fallback chain:\n",
    "- Primary: Real-time API\n",
    "- Secondary: 5-minute cached data\n",
    "- Tertiary: Daily aggregated data\n",
    "- Final: Default static response\n",
    "\n",
    "### Exercise 3: Adaptive Circuit Breaker\n",
    "\n",
    "Build a circuit breaker that:\n",
    "- Adjusts thresholds based on error rate trends\n",
    "- Has different thresholds for different error types\n",
    "- Provides detailed health metrics\n",
    "\n",
    "### Exercise 4: Comprehensive Error Handler\n",
    "\n",
    "Combine all patterns:\n",
    "- Retry transient failures\n",
    "- Fall back on persistent failures\n",
    "- Open circuit on cascading failures\n",
    "- Apply timeouts to all operations\n",
    "- Log all errors for monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c5b0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise playground - implement your solutions here!\n",
    "\n",
    "async def smart_retry_exercise():\n",
    "    \"\"\"\n",
    "    Exercise 1: Build retry with error type filtering\n",
    "    \"\"\"\n",
    "    # TODO: Implement selective retry logic\n",
    "    pass\n",
    "\n",
    "async def multi_tier_fallback_exercise():\n",
    "    \"\"\"\n",
    "    Exercise 2: Build multi-tier fallback chain\n",
    "    \"\"\"\n",
    "    # TODO: Implement 4-tier fallback\n",
    "    pass\n",
    "\n",
    "async def adaptive_circuit_breaker_exercise():\n",
    "    \"\"\"\n",
    "    Exercise 3: Build adaptive circuit breaker\n",
    "    \"\"\"\n",
    "    # TODO: Implement dynamic thresholds\n",
    "    pass\n",
    "\n",
    "async def comprehensive_error_handler_exercise():\n",
    "    \"\"\"\n",
    "    Exercise 4: Combine all error handling patterns\n",
    "    \"\"\"\n",
    "    # TODO: Implement combined error handling\n",
    "    pass\n",
    "\n",
    "print(\" Exercise templates ready - implement your solutions above!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d22ffe",
   "metadata": {},
   "source": [
    "##  What's Next?\n",
    "\n",
    "Congratulations! You've mastered error handling and recovery patterns!\n",
    "\n",
    "You now know how to:\n",
    "-  Implement retry logic with exponential backoff\n",
    "-  Build fallback strategies for graceful degradation\n",
    "-  Use circuit breakers to prevent cascading failures\n",
    "-  Apply timeout protection to prevent hangs\n",
    "-  Combine patterns for robust production systems\n",
    "\n",
    "**Coming in Future Tutorials:**\n",
    "- **Tutorial 10: Monitoring & Observability** - Logging, metrics, tracing, debugging\n",
    "- **Tutorial 11: Testing AI Workflows** - Unit tests, integration tests, mocking\n",
    "- **Tutorial 12: Production Deployment** - Best practices, security, scaling, CI/CD\n",
    "\n",
    "---\n",
    "\n",
    "### Quick Reference\n",
    "\n",
    "**Retry Pattern:**\n",
    "```python\n",
    "for attempt in range(max_retries):\n",
    "    try:\n",
    "        return await operation()\n",
    "    except TransientError:\n",
    "        await asyncio.sleep(delay)\n",
    "        delay *= 2  # Exponential backoff\n",
    "```\n",
    "\n",
    "**Fallback Pattern:**\n",
    "```python\n",
    "try:\n",
    "    return await primary()\n",
    "except:\n",
    "    try:\n",
    "        return await secondary()\n",
    "    except:\n",
    "        return cached_response()\n",
    "```\n",
    "\n",
    "**Circuit Breaker Pattern:**\n",
    "```python\n",
    "if circuit_open:\n",
    "    raise ServiceUnavailable(\"Circuit open\")\n",
    "try:\n",
    "    result = await service()\n",
    "    close_circuit()\n",
    "    return result\n",
    "except:\n",
    "    open_circuit()\n",
    "    raise\n",
    "```\n",
    "\n",
    "**Timeout Pattern:**\n",
    "```python\n",
    "try:\n",
    "    return await asyncio.wait_for(operation(), timeout=30)\n",
    "except asyncio.TimeoutError:\n",
    "    raise OperationTimeout()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "** Great job completing Tutorial 09!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}